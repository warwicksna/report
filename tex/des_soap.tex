\section{SOAP}

An important part of our project was connecting our code running on the Hadoop cluster to the C\# visualiser created by last year's project group. Therefore, we had to define a means of communicating between these different modules -- as these modules would be running on different machines, this interface had to be exposed as a web service. We chose to implement this communication interface in SOAP; the reason for this choice is detailed below.

\subsection{Choice of SOAP over REST}

[http://www.infoq.com/articles/rest-soap-when-to-use-each]

The two leading candidates for the communication interface were REST and SOAP. These are usually compared side by side, although strictly speaking SOAP is a communications protocol wheras REST is more of an architectural pattern that sits on top of HTTP.

\subsubsection{Advantages of REST}

REST, short for REpresentational State Transfer, is an architectural pattern for using HTTP as a web service. The motivation behind REST is that HTTP already contains a rich vocabulary for manipulating resources -- GET, POST, PUT and so on -- and thus, the logic goes, avoid reimplementing these commands in a complicated new protocol such as SOAP.

[http://www.ajaxonomy.com/2008/xml/web-services-part-1-soap-vs-rest]

The benefits of REST, as defined by [ajaxonomy] and [infoQ], are:
\begin{itemize}
\item It is language and platform agnostic.
\item It is simpler than SOAP, as it does not require an additional messaging
layer.
\item It is closer to the philosopy of the web as originally defined by it's
creator, Tim Berners-Lee.
\item It is able to make use of the built-in capabilities provided by the HTTP
protocol.
\end{itemize}

\subsubsection{Advantages of SOAP}

SOAP, short for Simple Object Access Protocol, is a protocol designed for exchanging structured data via XML. Normally the SOAP framework will abstract away the XML from the end user, using a remote procedure call (RPC) -based interface. An RPC interface is exposed to the application programmer in a simple way; they define a function or method on the server side, and then call that function on the client side. Creating and parsing XML messages is handled by the SOAP library used.

Unlike REST, SOAP can run on top of any transport layer -- this may be HTTP or something else.

The benefits of SOAP [same sources as above], are:
\begin{itemize}
\item Unlike REST, it enables the developer to define their own vocabulary of
verbs to suit the target domain.
\item It is language, platform *and* transport agnostic.
\item It is designed to handle distributed computing environments.
\item It is the predominant standard for web services, meaning there is a
greater level of support in different programming languages.
\item It features built-in error handling.
\end{itemize}

For these reasons, we chose to use SOAP as the communications protocol.

\subsection{Architecture Overview}

[Insert Diagram Here]

The SOAP communication module followed a standard client-server model. The SOAP server (written in Python) would run on the same machine as the Hadoop head node. Python's subprocess module, which lets shell commands be executed from within Python scripts, would be used to allow the SOAP server to control the Hadoop cluster.

Two SOAP clients were written. One was a command line client, also written in Python. The second was the C\#-based visualiser written by last year's project group, which would be modified to send SOAP commands.

During the implementation of the server, one major change to the design proved neccesary; this was modifying it so that it worked in a multi-threaded manner, with one Hadoop task being ran per thread. The reason for this change is detailed in the implementation section below.

Other changes that were made during the design phase included sending large files as base 64-encoding strings, rather than byte arrays, and giving the server the ability to execute algorithms as Python scripts as well as JAR files.

\subsection{Message Structure}

We decided that the API needed to support the following commands:

\begin{itemize}
    \item {\tt upload\_data\_set}

    \begin{description}        
        \item[Arguments] data\_set\_name (string), data\_set (string)
        
        \item[Returns] String
        
        \item[Description] Takes an data\_set (as a base 64-encoded string), and
writes it to a file in the snat\_data\_sets directory on HDFS. Returns
success/failure message.
    \end{description}
    
    \item {\tt upload\_algorithm}

    \begin{description}        
        \item[Arguments] algorithm\_name (string), class\_name (string),
jar\_file (string)
        
        \item[Returns] String
        
        \item[Description] Takes an jar file (as a base 64-encoded string), and
writes it to a file in the algorithms directory (on the regular file system). It
also writes to a text file that keeps of a record of all the uploaded
algorithms. Returns success/failure message. (Note: although the SOAP server can
execute algorithms as either JAR files or Python scripts, currently only JAR
files can be uploaded).
    \end{description}
    
    \item {\tt get\_algorithms}

    \begin{description}        
        \item[Arguments] None
        
        \item[Returns] List[String]
        
        \item[Description] Returns a list of all the algorithms contained in the
algorithms directory.
    \end{description}
    
    \item {\tt get\_data\_sets}

    \begin{description}        
        \item[Arguments] None
        
        \item[Returns] List[String]
        
        \item[Description] Returns a list of all the data sets contained in the
snat\_datasets directory.
    \end{description}
    
    \item {\tt execute\_algorithm}

    \begin{description}        
        \item[Arguments] algorithm\_name (string), data\_set\_name (string),
num\_nodes (integer), command\_line\_args
        
        \item[Returns] Integer
        
        \item[Description] Looks up the algorithm named algorithm\_name. If it
references a JAR file, run a Hadoop job with that JAR. If it references a Python
script, run that script. All jobs are executed in background threads; returns an
integer identifying the thread.
    \end{description}
    
    \item {\tt get\_results}

    \begin{description}        
        \item[Arguments] thread\_id (integer)
        
        \item[Returns] String
        
        \item[Description] Takes a thread\_id referencing a Hadoop job running
in the background. If the job has terminated, returns the output as a base
64-encoded string.
    \end{description}
    
    \item {\tt show\_statys}

    \begin{description}        
        \item[Arguments] required\_data (string)
        
        \item[Returns] String
        
        \item[Description] Currently, takes a port number for one of the Hadoop
logging pages running on localhost, and returns the contents of that page.
    \end{description}
\end{itemize}

The command line client's interface was designed to be familiar to anyone who has used standard UNIX based commands like ‘ls’:

                   Arguments                            Effect
./snat.py

     s                                                                  Status

     e    <algorithm id> <dataset id> <#nodes> <args>        Execute

     la                                                                  List algorithms

     ld                                                                  List datasets

     ua   <name> <filename> <job class>                          Upload algorithm

     ud   <name> <filename>                                       Upload dataset


